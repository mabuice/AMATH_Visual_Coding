{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dfe47c2",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/mabuice/AMATH_Visual_Coding/blob/main/Homework_Decoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d25d5a",
   "metadata": {
    "id": "73d25d5a"
   },
   "source": [
    "<div style=\"background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
    "<h3> This notebook will explore decoding using the Allen Brain Observatory data </h3>\n",
    "    \n",
    "In this notebook, we'll look at decoding using different models, different definitions of the design matrix, and different neural populations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fZwHuV7_uqNp",
   "metadata": {
    "id": "fZwHuV7_uqNp"
   },
   "outputs": [],
   "source": [
    "# @title Run to initialize Allen Brain Observatory on Colab {display-mode: \"form\" }\n",
    "# run only once per runtime/session, and only if running in colab\n",
    "# the runtime will need to restart after\n",
    "%%capture\n",
    "!apt install s3fs\n",
    "!pip install allensdk\n",
    "!mkdir -p /data/allen-brain-observatory/\n",
    "!s3fs allen-brain-observatory /data/allen-brain-observatory/ -o public_bucket=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b07a0",
   "metadata": {
    "id": "328b07a0"
   },
   "source": [
    "### Standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac50c84c",
   "metadata": {
    "id": "ac50c84c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eaa6e4",
   "metadata": {
    "id": "50eaa6e4"
   },
   "source": [
    "### Allen Brain Observatory set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212135d6",
   "metadata": {
    "id": "212135d6"
   },
   "outputs": [],
   "source": [
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "\n",
    "manifest_file = '../data/allen-brain-observatory/visual-coding-2p/manifest.json'\n",
    "boc = BrainObservatoryCache(manifest_file=manifest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddbabd3",
   "metadata": {
    "id": "2ddbabd3"
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "The command below returns a list of dictionaries containing information about the experiment sessions.  As we saw in the main notebook, you can use optional arguments to specify subsets of experiment sessions.  (Hint:  use the help function to see other ways of choosing sessions.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca663637",
   "metadata": {
    "id": "ca663637"
   },
   "outputs": [],
   "source": [
    "exps = boc.get_ophys_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T-fPGw30MSLk",
   "metadata": {
    "id": "T-fPGw30MSLk"
   },
   "source": [
    "The following function will grab the data_set object for a given session_id.  The last two lines will extract the dF/F traces and the stimulus table for a given stimulus type.  \n",
    "\n",
    "Some other stimulus types are `natural_scenes` and `static_gratings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VabuvKlDMRTb",
   "metadata": {
    "id": "VabuvKlDMRTb"
   },
   "outputs": [],
   "source": [
    "session_id = ?\n",
    "data_set = boc.get_ophys_experiment_data(session_id)\n",
    "\n",
    "timestamps, dff = data_set.get_dff_traces()\n",
    "stim_table = data_set.get_stimulus_table('drifting_gratings')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf7399e",
   "metadata": {
    "id": "3cf7399e"
   },
   "source": [
    "**Exercise 1:** Use a different decoder and repeat the same analysis.  Good decoders to try are Logistic Regression, Support Vector Machine, K-Means.\n",
    "\n",
    "Logistic Regression:\n",
    "https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "Support Vector Machine:\n",
    "https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "(Note:  look through the documentation to see what parameters govern these decoders.  How should you set them?  What effect do they have on the performance of your classifier?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086b0493",
   "metadata": {
    "id": "086b0493"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2342cac1",
   "metadata": {
    "id": "2342cac1"
   },
   "source": [
    "**Exercise 2:** Use a different stimulus type.  In addition to ‘drifting_gratings’, there are also ‘natural_scenes’ and ‘static_gratings’.  Find a session with these stimuli and try decoding the stimulus condition.\n",
    "\n",
    "(Hint:  use the function given above to get a list of experiments and convert it to a dataframe).*italicized text*\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T2yauTHcWmwD",
   "metadata": {
    "id": "T2yauTHcWmwD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "664f1572",
   "metadata": {
    "id": "664f1572"
   },
   "source": [
    "**Exercise 3:** Compare the decoding performance between sessions from different areas.  Does decoding of drifting gratings work better in VISp compared to other areas?  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dvB-dd9RWp3T",
   "metadata": {
    "id": "dvB-dd9RWp3T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "SO7vsaHYyS8l",
   "metadata": {
    "id": "SO7vsaHYyS8l"
   },
   "source": [
    "**Exercise 4:**  Compare the decoding performance between sessions from different areas of similar depth.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dlOE2fMpXpxg",
   "metadata": {
    "id": "dlOE2fMpXpxg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "leBBxF_JyOpf",
   "metadata": {
    "id": "leBBxF_JyOpf"
   },
   "source": [
    "**Exercise 5:** Compare the decoding performance between sessions from different Cre lines of VISp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fee9e4",
   "metadata": {
    "id": "88fee9e4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "pf2wJg8pya0F",
   "metadata": {
    "id": "pf2wJg8pya0F"
   },
   "source": [
    "**Exercise 6**:  Compute the design matrix using a different time window or different time offset relative to the stimulus.  Redo the decoding.  What happens as you move the window from before to after the stimulus presentation time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243k1WSvy3BK",
   "metadata": {
    "id": "243k1WSvy3BK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
